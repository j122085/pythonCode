{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "with open(r\"D:\\pyCharm\\愛評網套餐\\已完成\\TainanUnique.json\") as f:\n",
    "    allcontent=json.load(f)\n",
    "samplecontent=allcontent[0][\"comment\"][0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'簡單、傳統的安平豆花，純白的豆花特別的挑逗我們的胃口。安平，兼具了台南傳統與現代的一個區域，而作為安平代表的傳統美食，一如我們所知的就是安平豆花與周氏蝦捲了。今天，帶點炎熱的天氣，是來點清涼降火冰品的好日子，當然是來喊個豆花消暑了，而吃安平豆花當然是要去最著名的同記安平豆花。同記安平豆花光是在安平就有兩個店面，相距只有一公里左右，今天我們來到的是總店。雖然是平日下午，但店內一副忙碌的景象。剛有客人離開，趕緊搶佔一桌，店內用的是原木的大張長桌以及長椅，很有古風呢。牆上擺的是這些年來到過安平豆花的名人，真的是不少。同記安平豆花在安平已經有四十多年的歷史了，取名「同」記是因為最早的創始人黃慶同名字中有個同字。從小推車一路叫賣開始，到現在成為台南十大傳統名產之一，其中艱辛不足與外人道(所以我們當然不知道了，跳過)；從1993年成立店面後，原本大家稱呼的安平豆花也正式的掛上了「同記」的前綴了。不過雖然安平區的豆花店逐漸變多，但是大家只要說到安平豆花，就知道是指同記安平豆花說。快快來點豆花了，種類並不是非常多，但是道道都是經典。我們選了最正宗、最傳統的紅豆豆花跟綠豆豆花各一碗。一切依古法精製，非基因改造有機黃豆製作，光看成色就令人心動。紅豆部分，則是由來自屏東萬丹的極品紅豆，經過數小時的熬煮後，以最佳的紅豆香氣呈現在我們眼前。好吃，加點一碗紅豆豆花，每顆紅豆都保持著完整的外觀，入口都很有口感說。每一口豆花的口感都是軟嫩細緻，入口傳統的黃豆香氣，手工製作跟用洋菜粉勾芡出來的口感就是不一樣。另外綠豆豆花則除了軟透心的綠豆外，搭著嫩豆花以及微甜的甘蔗糖水一起入口，高雅芬芳得猶如在咖啡館享用下午茶。好吃的豆花，來到安平千萬不要錯過，在老街逛累了，順便來碗冰涼透心的豆花，真是大享受啊！同記安平豆花(總店)(09:00~23:00)台南市安平區安北路433號(06-3915385‧3915057)http://www.tongji.com.tw/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplecontent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\詞庫\\jieba_dict\\stopwords.txt\",encoding=\"utf-8\") as st:\n",
    "    stopwords=st.read()\n",
    "stopwords=stopwords.split(\"\\n\")\n",
    "\n",
    "import jieba\n",
    "samplecut=\" \".join([word for word in jieba.cut(samplecontent) if word not in stopwords  and '\\u4e00' <= word <= '\\u9fff' ])\n",
    "from collections import Counter\n",
    "samplewordcount=Counter(samplecut.split(\" \")).most_common(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "#samplecontent\n",
    "#samplecut\n",
    "#samplewordcount\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from pprint import pprint\n",
    "newsgroups_train=fetch_20newsgroups(subset='train')\n",
    "pprint(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories =['alt.atheism','comp.graphics','sci.med','soc.religion.christian']\n",
    "twenty_train=fetch_20newsgroups(subset='train',categories=categories)\n",
    "#文字轉向量矩陣\n",
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#被轉的文字資料\n",
    "twenty_train.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將舉陣做TF_IDF得到各詞在該篇文章的詞的特徵數字(數字愈高愈有代表性)\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# for i in X_train_tfidf:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用這些tfidf詞特徵數字 跟文章 種類編碼(特徵標籤) 做模型\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "clf = NearestCentroid().fit(X_train_tfidf,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15521)\t1\n",
      "  (0, 18474)\t1\n",
      "  (0, 20537)\t1\n",
      "  (1, 14048)\t1\n",
      "  (1, 15628)\t1\n",
      "  (1, 18474)\t1\n",
      "  (1, 23733)\t1\n",
      "  (1, 23790)\t1\n",
      "  (1, 32142)\t1\n"
     ]
    }
   ],
   "source": [
    "#隨便拿兩個文章，也把它變成TFIDF>並用剛剛的模型預測這兩篇文章的種類(特徵標籤)\n",
    "docs_new=['God is love','OpenGL on the GPU is fast']\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "print(X_new_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 20537)\t0.809401056239\n",
      "  (0, 18474)\t0.255894264685\n",
      "  (0, 15521)\t0.528571712694\n",
      "  (1, 32142)\t0.0891122234242\n",
      "  (1, 23790)\t0.600483554876\n",
      "  (1, 23733)\t0.128412754679\n",
      "  (1, 18474)\t0.100340184397\n",
      "  (1, 15628)\t0.677839555469\n",
      "  (1, 14048)\t0.381384400353\n"
     ]
    }
   ],
   "source": [
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "print(x_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted =clf.predict(x_new_tfidf)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love'=>soc.religion.christian\n",
      "'OpenGL on the GPU is fast'=>comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc,category in zip(docs_new,predicted):\n",
    "    print(\"%r=>%s\"%(doc,twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new=['God is love','OpenGL on the GPU is fast']\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(x_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love'=>soc.religion.christian\n",
      "'OpenGL on the GPU is fast'=>comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc,category in zip(docs_new,predicted):\n",
    "    print(\"%r=>%s\"%(doc,twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=KNeighborsClassifier().fit(X_train_tfidf,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_new=['God is love','OpenGL on the GPU is fast']\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(x_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love'=>soc.religion.christian\n",
      "'OpenGL on the GPU is fast'=>comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc,category in zip(docs_new,predicted):\n",
    "    print(\"%r=>%s\"%(doc,twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=svm.SVC(kernel='linear').fit(X_train_tfidf,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_new=['God is love','OpenGL on the GPU is fast']\n",
    "X_new_counts= count_vect.transform(docs_new)\n",
    "x_new_tfidf=tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(x_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love'=>soc.religion.christian\n",
      "'OpenGL on the GPU is fast'=>comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc,category in zip(docs_new,predicted):\n",
    "    print(\"%r=>%s\"%(doc,twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
