{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"D:/Data/JsonData/TainanFood/AnalyzeTable.json\") as f:\n",
    "    x=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import sys \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_wordcloud = WordCloud().generate(x[0]['contentcut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(my_wordcloud)\n",
    "plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "from os import path \n",
    "from scipy.misc import imread \n",
    "import jieba \n",
    "import sys \n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開啟本體TXT檔案 \n",
    "# text = open('weixin.txt').read() \n",
    "# 結巴分詞 cut_all=True 設定為全模式 \n",
    "# wordlist = jieba.cut(text) #cut_all = True \n",
    "# 使用空格連線 進行中文分詞 \n",
    "# wl_space_split = \" \".join(wordlist) \n",
    "stopadd=[\"臺南\",\"菜色\",\"味道\",\"真的\",\"店家\",\"這道\",\"感覺\",\"比較\",\"用餐\",\"搭配\",\n",
    "         \"料理\",\"空間\",\"一個\",\"地方\",\"台南市\",\"台南\",\"口味\",\"店員\",'一起','一段',\n",
    "         '部分','餐點','地方','覺得','廁所','二樓',\"看到\",\"市場\",\"地址\",\"三段\",\"一段\",\n",
    "         '兩段','中西區','海安','一盒','會館','座位','選擇','下午','提供','制式','使用',\n",
    "         '北區','營業時間','電話','美食','一份','朋友','東西','一下','來到','一些','二段',\n",
    "         '有點','應該','老闆','推薦','這家','一直','菜單','想法','平路','府連',\n",
    "         '喜歡','東區','整個','時間','店內','國華','台北','聽說','升級','套餐',\n",
    "         '餐廳','相當','店內','裡面','一點','一口','知道','已經','這是','客人']\n",
    "stopwordset = set()\n",
    "with open('D:/WordLibrary/JiebaUse/stopwords.txt', 'r', encoding='utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "for i in stopadd:\n",
    "    stopwordset.add(i)\n",
    "import json \n",
    "with open(\"D:/Data/JsonData/TainanFood/bigtable_1.3.json\") as f:\n",
    "    x=json.load(f)\n",
    "    \n",
    "for dien,dirname in zip(x,os.listdir('D:/Data/GraphData/pixiv_good/small')):\n",
    "    if not os.path.exists(\"D:/Data/GraphData/\"+dien['name']+\".jpg\"):\n",
    "        \n",
    "        wl_space_split=dien['contentcut']\n",
    "    #     if wl_space_split!=[]:\n",
    "        # print (wl_space_split)\n",
    "        # 讀取mask/color圖片__file__ \n",
    "        try:\n",
    "            w = path.dirname('D:/Data/GraphData/') \n",
    "            #分出像素及色彩\n",
    "            nana_coloring = imread(r\"D:\\Data\\GraphData\\circle\\14071780_p0_master1200.jpg\") \n",
    "            # 對分詞後的文本生成詞雲 \n",
    "            my_wordcloud = WordCloud( background_color = 'white', # 設定背景顏色 \n",
    "                                     mask = nana_coloring, # 設定背景圖片 \n",
    "                                     max_words = 200, # 設定最大現實的字數 \n",
    "                                     stopwords = stopwordset, # 設定停用詞 \n",
    "                                     max_font_size = 100, # 設定字體最大值 \n",
    "                                     random_state = 50, # 設定有多少種隨機生成狀態，即有多少種配色方案 \n",
    "                                    ) \n",
    "            # generate word cloud \n",
    "            my_wordcloud.generate(wl_space_split) \n",
    "            # create coloring from image \n",
    "            image_colors = ImageColorGenerator(nana_coloring) \n",
    "            # recolor wordcloud and show \n",
    "            my_wordcloud.recolor(color_func=image_colors) \n",
    "            plt.imshow(my_wordcloud) # 顯示詞雲圖 \n",
    "            plt.axis(\"off\") # 是否顯示x軸、y軸下標 \n",
    "            plt.show() # save img \n",
    "            my_wordcloud.to_file(path.join(w, dien['name']+\".jpg\"))\n",
    "        except:\n",
    "            my_wordcloud = WordCloud().generate(\"你沒有評論 沒有評論 沒評論 沒有_評論\")\n",
    "            try:\n",
    "                my_wordcloud.to_file(path.join(w, dien['name']+\".jpg\"))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nana_coloring = imread(\"D:/Data/GraphData/pixiv_good/35919072.jpg\")\n",
    "\n",
    "nana_coloring[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"D:/Data/JsonData/TainanFood/bigtable_1.0.json\") as f:\n",
    "    x=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][\"contentcut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwordset = set()\n",
    "with open('D:/WordLibrary/JiebaUse/stopwords.txt', 'r', encoding='utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopadd=[\"臺南\",\"菜色\",\"味道\",\"真的\",\"店家\",\"這道\",\"感覺\",\"比較\",\"用餐\",\"搭配\",\n",
    "         \"料理\",\"空間\",\"一個\",\"地方\",\"台南市\",\"台南\",\"口味\",\"店員\",'一起','一段',\n",
    "         '部分','餐點','地方','覺得','廁所','二樓',\"看到\",\"市場\",\"地址\",\"三段\",\"一段\",\n",
    "         '兩段','中西區','海安','一盒','會館','座位','選擇','下午','提供','制式','使用',\n",
    "         '北區','營業時間','電話','美食','一份','朋友','東西','一下','來到','一些','二段',\n",
    "         '有點','應該','老闆','推薦','這家','一直']\n",
    "stopwordset = set()\n",
    "with open('D:/WordLibrary/JiebaUse/stopwords.txt', 'r', encoding='utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "for i in stopadd:\n",
    "    stopwordset.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
