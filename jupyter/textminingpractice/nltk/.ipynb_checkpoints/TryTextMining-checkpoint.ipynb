{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\pyCharm\\\\Aipingjsongetopentimefinish\\\\TainanUnique.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eeb402d2f40a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\pyCharm\\Aipingjsongetopentimefinish\\TainanUnique.json\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mallcontent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mDienlist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallcontent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\pyCharm\\\\Aipingjsongetopentimefinish\\\\TainanUnique.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter\n",
    "with open(\"D:\\pyCharm\\Aipingjsongetopentimefinish\\TainanUnique.json\") as f:\n",
    "    allcontent=json.load(f)\n",
    "Dienlist=[i[\"name\"] for i in allcontent]\n",
    "stylelist=[i[\"style\"] for i in allcontent]\n",
    "for i in Dienlist:\n",
    "    jieba.add_word(i)\n",
    "for i in stylelist:\n",
    "    jieba.add_word(i)\n",
    "with open(\"D:\\詞庫\\jieba_dict\\stopwords.txt\",encoding=\"utf-8\") as f:\n",
    "    a=f.read()\n",
    "    stopwords=a.split(\"\\n\")\n",
    "\n",
    "with open(\"D:\\詞庫\\canonical-correlation-clustering\\正面詞無重複_9365詞.txt\",encoding=\"big5\") as f:\n",
    "    goodwords=f.read()\n",
    "\n",
    "with open(\"D:\\詞庫\\canonical-correlation-clustering\\負面詞無重複_11230詞.txt\",encoding=\"big5\") as b:\n",
    "    badwords=b.read()\n",
    "badwords=badwords.split(\"\\n\")\n",
    "goodwords=goodwords.split(\"\\n\")\n",
    "for i in allcontent[60][\"comment\"]:\n",
    "    co=Counter(jieba.cut(i[\"content\"]))\n",
    "    cou=Counter({i:co[i] for i in co if i not in stopwords})\n",
    "    \n",
    "    good = [{i:cou[i]} for i in cou if i in goodwords]\n",
    "    bad = [{i:cou[i]} for i in cou if i in badwords]\n",
    "# g=0\n",
    "# b=0\n",
    "# for v in good:\n",
    "#     g+=good[v]\n",
    "# for v in bad:\n",
    "#     b+=bad[v]\n",
    "print(good)\n",
    "print(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allcontent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-41263445da06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mallcontent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"comment\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"content\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'allcontent' is not defined"
     ]
    }
   ],
   "source": [
    "allcontent[15][\"comment\"][1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google is one of the best companies in the world.\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(\"Google is one of the best companies in the world. I constantly google myself to see what I'm up to.\")\n",
    "nouns=[\"NN\",\"NNS\",\"NNP\",\"NNPS\"]\n",
    "for sentence in sentences:\n",
    "    if \"google\" in sentence.lower():\n",
    "        taggedWords = pos_tag(word_tokenize(sentence))\n",
    "        for word in taggedWords:\n",
    "            if word[0].lower() == \"google\" and word[1] in nouns:\n",
    "                print(sentence)\n",
    "#         print(taggedWords)\n",
    "#     print(sentence.lower())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('constantly', 'RB'),\n",
       " ('google', 'VBP'),\n",
       " ('myself', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('up', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('companies', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('constantly', 'RB'),\n",
       " ('google', 'VBP'),\n",
       " ('myself', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('up', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=word_tokenize(\"Google is one of the best companies in the world. I constantly google myself to see what I'm up to.\")\n",
    "pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sinica_treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一', '友情', '嘉珍', '和', '我', '住在', '同一條', '巷子', '我們', ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinica_treebank.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一Neu\n",
      "友情Nad\n",
      "嘉珍Nba\n",
      "和Caa\n",
      "我Nhaa\n",
      "住在VC1\n",
      "同一條DM\n",
      "巷子Nab\n"
     ]
    }
   ],
   "source": [
    "for (key, var) in sinica_treebank.tagged_words()[:8]:\n",
    "    print(\"%s%s\"%(key,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sinica_treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一', '友情', '嘉珍', '和', '我', '住在', '同一條', '巷子', '我們', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinica_treebank.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['嘉珍', '打開', '了', '門']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinica_treebank.sents()[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LazyModule 'nltk.toolbox'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sinica_treebank.parsed_sents()[3].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
